{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27a977a6-096e-4ee1-887f-7717e4603b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting evaluate\n",
      "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-2.16.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from evaluate) (1.26.2)\n",
      "Collecting dill (from evaluate)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: pandas in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from evaluate) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from evaluate) (4.66.1)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from evaluate) (0.19.4)\n",
      "Requirement already satisfied: packaging in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Collecting responses<0.19 (from evaluate)\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting nltk (from rouge_score)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.14.0 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: filelock in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Collecting pyarrow>=8.0.0 (from datasets>=2.0.0->evaluate)\n",
      "  Downloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets>=2.0.0->evaluate)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting aiohttp (from datasets>=2.0.0->evaluate)\n",
      "  Downloading aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
      "Collecting click (from nltk->rouge_score)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from nltk->rouge_score) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from nltk->rouge_score) (2023.12.25)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets>=2.0.0->evaluate)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.16.0-py3-none-any.whl (507 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=be6b99b6de2151b578955b3fa7bf65ded92c1177058f3c28ec773ffa54102fd3\n",
      "  Stored in directory: /home/sergiu/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -orch (/mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, frozenlist, dill, click, async-timeout, absl-py, yarl, responses, nltk, multiprocess, aiosignal, rouge_score, aiohttp, datasets, evaluate\n",
      "Successfully installed absl-py-2.0.0 aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 click-8.1.7 datasets-2.16.0 dill-0.3.7 evaluate-0.4.1 frozenlist-1.4.1 multidict-6.0.4 multiprocess-0.70.15 nltk-3.8.1 pyarrow-14.0.2 pyarrow-hotfix-0.6 responses-0.18.0 rouge_score-0.1.2 xxhash-3.4.1 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "# !pip install sentencepiece\n",
    "!pip install evaluate rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7edc68af-31ab-498b-b962-8a717e42af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import XLNetTokenizer, XLNetLMHeadModel, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44c725f-6f77-4104-ad39-44432dceaddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd9f199-82da-4a67-a8b4-003cf5781867",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c68296-7d30-413a-a176-adf2af37e1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsela_path = 'newsela/'\n",
    "newsela_metadata = os.path.join(newsela_path, 'articles_metadata.csv')\n",
    "newsela_articles_dir = os.path.join(newsela_path, 'articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c1fb39-4783-4124-8be3-eca6003593f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slug</th>\n",
       "      <th>language</th>\n",
       "      <th>title</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>version</th>\n",
       "      <th>filename</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10dollarbill-woman</td>\n",
       "      <td>en</td>\n",
       "      <td>Tubman, Perkins or Roosevelt? Woman on $10 bil...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10dollarbill-woman.en.0.txt</td>\n",
       "      <td>WASHINGTON — An abolitionist. The longest-serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10dollarbill-woman</td>\n",
       "      <td>en</td>\n",
       "      <td>Americans weigh in to choose the woman who wil...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10dollarbill-woman.en.1.txt</td>\n",
       "      <td>WASHINGTON — The all-male lineup on American m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10dollarbill-woman</td>\n",
       "      <td>en</td>\n",
       "      <td>The $10 question: Who will be the new face on ...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "      <td>10dollarbill-woman.en.2.txt</td>\n",
       "      <td>WASHINGTON — It's time for a woman to be honor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10dollarbill-woman</td>\n",
       "      <td>en</td>\n",
       "      <td>New $10 bill will have a theme and a woman's p...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10dollarbill-woman.en.3.txt</td>\n",
       "      <td>WASHINGTON — It is time that a woman be on Ame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10dollarbill-woman</td>\n",
       "      <td>en</td>\n",
       "      <td>We will soon have an American woman's face on ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>10dollarbill-woman.en.4.txt</td>\n",
       "      <td>WASHINGTON — Pictures of men are on all Americ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 slug language  \\\n",
       "0  10dollarbill-woman       en   \n",
       "1  10dollarbill-woman       en   \n",
       "2  10dollarbill-woman       en   \n",
       "3  10dollarbill-woman       en   \n",
       "4  10dollarbill-woman       en   \n",
       "\n",
       "                                               title  grade_level  version  \\\n",
       "0  Tubman, Perkins or Roosevelt? Woman on $10 bil...         12.0        0   \n",
       "1  Americans weigh in to choose the woman who wil...          8.0        1   \n",
       "2  The $10 question: Who will be the new face on ...          6.0        2   \n",
       "3  New $10 bill will have a theme and a woman's p...          5.0        3   \n",
       "4  We will soon have an American woman's face on ...          3.0        4   \n",
       "\n",
       "                      filename  \\\n",
       "0  10dollarbill-woman.en.0.txt   \n",
       "1  10dollarbill-woman.en.1.txt   \n",
       "2  10dollarbill-woman.en.2.txt   \n",
       "3  10dollarbill-woman.en.3.txt   \n",
       "4  10dollarbill-woman.en.4.txt   \n",
       "\n",
       "                                                text  \n",
       "0  WASHINGTON — An abolitionist. The longest-serv...  \n",
       "1  WASHINGTON — The all-male lineup on American m...  \n",
       "2  WASHINGTON — It's time for a woman to be honor...  \n",
       "3  WASHINGTON — It is time that a woman be on Ame...  \n",
       "4  WASHINGTON — Pictures of men are on all Americ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(newsela_metadata)\n",
    "df = pd.read_csv('newsela_all.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0579b6c2-966d-428e-95f5-5208cffa4f71",
   "metadata": {},
   "source": [
    "### One-time Processing for text ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "259831a6-3c2c-44b2-bab7-241279939a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_file(file_path):\n",
    "#     try:\n",
    "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#             return file.read()\n",
    "#     except Exception as e:\n",
    "#         # In case of error, return NaN or some error indication\n",
    "#         return pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e50e745-b684-45d7-b321-34aca5f97117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# texts = []\n",
    "\n",
    "# for i, row in enumerate(df.itertuples()):\n",
    "#     file_path = os.path.join(newsela_articles_dir, row.filename)\n",
    "#     # print(file_path)\n",
    "#     file_text = read_file(file_path)\n",
    "#     # print(file_text)\n",
    "#     texts.append(file_text)\n",
    "\n",
    "# df['text'] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625fac25-e880-4c39-b98e-ccd854f86df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a488e9e-55a8-4d9e-a8fd-cabff4291bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('newsela_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2355b9-1a15-4c00-9bbf-8d1cb6630fb8",
   "metadata": {},
   "source": [
    "### Create Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d3961b-32c3-4371-a96b-fa3d743de6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 0 - 8629; Test index: 8630 - 10786\n"
     ]
    }
   ],
   "source": [
    "train_index = 8629 # 80% of the entire set\n",
    "test_index = df.shape[0] - train_index\n",
    "print(f\"Train rows: 0 - {train_index}; Test index: {train_index + 1} - {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "995b0920-172e-414f-96cb-ad32ca75aa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8629, 7) (2157, 7)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[:train_index]\n",
    "test_df = df[train_index:]\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bdcb531-b1f6-404f-ac9a-191a09ec305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = {\"train\": [], \"test\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e06e66e-c489-426c-8868-b7d4e1c780a8",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45f5663d-5df8-4ba1-887e-4b3d0af4d7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = train_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344a353f-9400-4776-aece-09af997ec502",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_slug = train_dict[0]['slug']\n",
    "tmp_texts = []\n",
    "tmp_titles = []\n",
    "\n",
    "for record in train_dict:\n",
    "    # Iterate through all the records belonging to a slug and save the texts\n",
    "    if record['slug'] == prev_slug:\n",
    "        tmp_texts.append(record['text'])\n",
    "        tmp_titles.append(record['title'])\n",
    "    # We've reached a new slug, so it's time to create the train/test record for the given slug\n",
    "    else:\n",
    "        for title, text in zip(tmp_titles[:-1], tmp_texts[:-1]):\n",
    "            dataset_dict[\"train\"].append(\n",
    "                {\n",
    "                    'text': text,\n",
    "                    'simplification': tmp_texts[-1],\n",
    "                    'title': title\n",
    "                }\n",
    "            )\n",
    "        prev_slug = record['slug']\n",
    "        prev_title = record['title']\n",
    "        tmp_texts = []       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c4fbe04-a9ad-429a-b045-d7de2ce3d0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5182\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_dict['train']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5a5fc-8d78-45be-9705-10ac1e48ea59",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6742fdf2-e778-4201-910e-13b0df15b35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = test_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ac5fe2f-16f4-4e91-a23d-9ccf4f3d4e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_slug = train_dict[0]['slug']\n",
    "tmp_texts = []\n",
    "tmp_titles = []\n",
    "\n",
    "for record in test_dict:\n",
    "    # Iterate through all the records belonging to a slug and save the texts\n",
    "    if record['slug'] == prev_slug:\n",
    "        tmp_texts.append(record['text'])\n",
    "        tmp_titles.append(record['title'])\n",
    "    # We've reached a new slug, so it's time to create the train/test record for the given slug\n",
    "    else:\n",
    "        for title, text in zip(tmp_titles[:-1], tmp_texts[:-1]):\n",
    "            dataset_dict[\"test\"].append(\n",
    "                {\n",
    "                    'text': text,\n",
    "                    'simplification': tmp_texts[-1],\n",
    "                    'title': title\n",
    "                }\n",
    "            )\n",
    "        prev_slug = record['slug']\n",
    "        prev_title = record['title']\n",
    "        tmp_texts = []       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bef6a1d3-557e-43a4-83ce-96f41eb21b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_dict['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda5ac5-4735-4a9b-8803-7bba17ee4e7d",
   "metadata": {},
   "source": [
    "### Train Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c028364-7822-4e71-b3fa-65ca0c0358ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9288874c-846d-40a3-9fcf-c1a78f945e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"simplify: \"\n",
    "inputs = []\n",
    "targets = []\n",
    "for doc in dataset_dict['train']:\n",
    "    inputs.append(prefix + doc['text'])\n",
    "    targets.append(doc['simplification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca5c1033-332b-4181-8757-98c34f8ff740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5182 5182\n"
     ]
    }
   ],
   "source": [
    "print(len(inputs), len(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ca39f34-4240-4225-bbcf-40cb3d8dd2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"simplify: \"\n",
    "test_inputs = []\n",
    "test_targets = []\n",
    "for doc in dataset_dict['test']:\n",
    "    test_inputs.append(prefix + doc['text'])\n",
    "    test_targets.append(doc['simplification'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f723c02-080a-4089-a366-89ce1e26bb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1292 1292\n"
     ]
    }
   ],
   "source": [
    "print(len(test_inputs), len(test_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4fb6f-6c04-413c-88dd-7ef4c28121de",
   "metadata": {},
   "source": [
    "#### Preprocess Train Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4b1cd6a-41b6-4300-91c4-71a99b2e4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(inputs, targets):\n",
    "    # inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, return_tensors='pt', max_length=1024, padding='max_length', truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=targets, return_tensors='pt', max_length=1024, padding='max_length', truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87c2fd97-649f-45ac-9905-73ed7bf64c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs, model_labels = preprocess_function(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19f4dda3-3803-4433-9676-aafe0ac989f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20375,    60,  9874,  ...,   461,     4,     3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs['input_ids'][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "984a1e4b-c98e-46af-8224-1b6ba4d75108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(model_inputs['input_ids'], model_labels['input_ids'])\n",
    "\n",
    "# Create a DataLoader\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59bb0770-b2b2-4611-8088-7dc5ce7f2db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_tokens_right(input_ids, pad_token_id):\n",
    "    \"\"\"Shift input ids one token to the right, and wrap the last non pad token (usually <eos>).\"\"\"\n",
    "    prev_output_tokens = input_ids.clone()\n",
    "    index_of_eos = (input_ids.ne(pad_token_id).sum(dim=1) - 1).unsqueeze(-1)\n",
    "    prev_output_tokens[:, 0] = input_ids.gather(1, index_of_eos).squeeze()\n",
    "    prev_output_tokens[:, 1:] = input_ids[:, :-1]\n",
    "    return prev_output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997d5952-dac8-4b92-b404-6b4948fdf008",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68efa4c0-a10d-4efc-9992-814cdebb377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XLNetLMHeadModel.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e7db043-4445-4345-9785-2ee7eb027791",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 4. Define Training Parameters\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb228fc8-26cf-4c55-9ebb-5fccd6660f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetLMHeadModel(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_loss): Linear(in_features=768, out_features=32000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7e73698-6279-4c01-9d13-5985d7918cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Step 100 Loss 5.026244163513184\n",
      "Epoch 0 Step 200 Loss 5.893657684326172\n",
      "Epoch 0 Step 300 Loss 4.964169979095459\n",
      "Epoch 0 Step 400 Loss 5.1959733963012695\n",
      "Epoch 0 Step 500 Loss 4.505870342254639\n",
      "Epoch 0 Step 600 Loss 4.594396591186523\n",
      "Epoch 0 Step 700 Loss 3.460613965988159\n",
      "Epoch 0 Step 800 Loss 4.547153472900391\n",
      "Epoch 0 Step 900 Loss 4.283635139465332\n",
      "Epoch 0 Step 1000 Loss 3.9535672664642334\n",
      "Epoch 0 Step 1100 Loss 4.520374298095703\n",
      "Epoch 0 Step 1200 Loss 6.07244348526001\n",
      "Average Training Loss: 4.940993779235416\n",
      "Epoch 1 Step 100 Loss 5.125080585479736\n",
      "Epoch 1 Step 200 Loss 3.9568779468536377\n",
      "Epoch 1 Step 300 Loss 4.50228214263916\n",
      "Epoch 1 Step 400 Loss 5.492114543914795\n",
      "Epoch 1 Step 500 Loss 4.65526008605957\n",
      "Epoch 1 Step 600 Loss 5.31953763961792\n",
      "Epoch 1 Step 700 Loss 3.8569183349609375\n",
      "Epoch 1 Step 800 Loss 4.194915294647217\n",
      "Epoch 1 Step 900 Loss 4.093446254730225\n",
      "Epoch 1 Step 1000 Loss 3.662853479385376\n",
      "Epoch 1 Step 1100 Loss 4.537163734436035\n",
      "Epoch 1 Step 1200 Loss 4.524852752685547\n",
      "Average Training Loss: 4.4248728595766025\n",
      "Epoch 2 Step 100 Loss 4.603614330291748\n",
      "Epoch 2 Step 200 Loss 4.217392921447754\n",
      "Epoch 2 Step 300 Loss 4.435378074645996\n",
      "Epoch 2 Step 400 Loss 4.7331438064575195\n",
      "Epoch 2 Step 500 Loss 4.359727382659912\n",
      "Epoch 2 Step 600 Loss 5.301181793212891\n",
      "Epoch 2 Step 700 Loss 4.332385063171387\n",
      "Epoch 2 Step 800 Loss 3.7514963150024414\n",
      "Epoch 2 Step 900 Loss 4.650548934936523\n",
      "Epoch 2 Step 1000 Loss 4.121835231781006\n",
      "Epoch 2 Step 1100 Loss 3.826198101043701\n",
      "Epoch 2 Step 1200 Loss 5.222508907318115\n",
      "Average Training Loss: 4.263375194536315\n",
      "Epoch 3 Step 100 Loss 4.717140197753906\n",
      "Epoch 3 Step 200 Loss 4.590120315551758\n",
      "Epoch 3 Step 300 Loss 4.780978202819824\n",
      "Epoch 3 Step 400 Loss 4.299923896789551\n",
      "Epoch 3 Step 500 Loss 4.794330596923828\n",
      "Epoch 3 Step 600 Loss 4.90772008895874\n",
      "Epoch 3 Step 700 Loss 5.2156596183776855\n",
      "Epoch 3 Step 800 Loss 4.793715953826904\n",
      "Epoch 3 Step 900 Loss 3.985318660736084\n",
      "Epoch 3 Step 1000 Loss 3.7246477603912354\n",
      "Epoch 3 Step 1100 Loss 3.602402687072754\n",
      "Epoch 3 Step 1200 Loss 4.329013347625732\n",
      "Average Training Loss: 4.173481227071197\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(4):  # Number of epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        # Assuming batch is a tuple of (input_ids, target_ids)\n",
    "        input_ids, target_ids = batch\n",
    "        input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n",
    "        \n",
    "        # Shift the target IDs for the decoder input and ignore the last token\n",
    "        decoder_input_ids = shift_tokens_right(target_ids, tokenizer.pad_token_id)\n",
    "\n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, labels=decoder_input_ids)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            print(f'Epoch {epoch} Step {step} Loss {loss.item()}')\n",
    "\n",
    "    # Calculate the average loss over the entire batch\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Average Training Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd8fe5-b679-47d3-b511-9c5a85524947",
   "metadata": {},
   "source": [
    "```\n",
    "Epoch 0 Step 100 Loss 5.026244163513184\r\n",
    "Epoch 0 Step 200 Loss 5.893657684326172\r\n",
    "Epoch 0 Step 300 Loss 4.964169979095459\r\n",
    "Epoch 0 Step 400 Loss 5.1959733963012695\r\n",
    "Epoch 0 Step 500 Loss 4.505870342254639\r\n",
    "Epoch 0 Step 600 Loss 4.594396591186523\r\n",
    "Epoch 0 Step 700 Loss 3.460613965988159\r\n",
    "Epoch 0 Step 800 Loss 4.547153472900391\r\n",
    "Epoch 0 Step 900 Loss 4.283635139465332\r\n",
    "Epoch 0 Step 1000 Loss 3.9535672664642334\r\n",
    "Epoch 0 Step 1100 Loss 4.520374298095703\r\n",
    "Epoch 0 Step 1200 Loss 6.07244348526001\r\n",
    "Average Training Loss: 4.940993779235416\r\n",
    "Epoch 1 Step 100 Loss 5.125080585479736\r\n",
    "Epoch 1 Step 200 Loss 3.9568779468536377\r\n",
    "Epoch 1 Step 300 Loss 4.50228214263916\r\n",
    "Epoch 1 Step 400 Loss 5.492114543914795\r\n",
    "Epoch 1 Step 500 Loss 4.65526008605957\r\n",
    "Epoch 1 Step 600 Loss 5.31953763961792\r\n",
    "Epoch 1 Step 700 Loss 3.8569183349609375\r\n",
    "Epoch 1 Step 800 Loss 4.194915294647217\r\n",
    "Epoch 1 Step 900 Loss 4.093446254730225\r\n",
    "Epoch 1 Step 1000 Loss 3.662853479385376\r\n",
    "Epoch 1 Step 1100 Loss 4.537163734436035\r\n",
    "Epoch 1 Step 1200 Loss 4.524852752685547\r\n",
    "Average Training Loss: 4.4248728595766025\r\n",
    "Epoch 2 Step 100 Loss 4.603614330291748\r\n",
    "Epoch 2 Step 200 Loss 4.217392921447754\r\n",
    "Epoch 2 Step 300 Loss 4.435378074645996\r\n",
    "Epoch 2 Step 400 Loss 4.7331438064575195\r\n",
    "Epoch 2 Step 500 Loss 4.359727382659912\r\n",
    "Epoch 2 Step 600 Loss 5.301181793212891\r\n",
    "Epoch 2 Step 700 Loss 4.332385063171387\r\n",
    "Epoch 2 Step 800 Loss 3.7514963150024414\r\n",
    "Epoch 2 Step 900 Loss 4.650548934936523\r\n",
    "Epoch 2 Step 1000 Loss 4.121835231781006\r\n",
    "Epoch 2 Step 1100 Loss 3.826198101043701\r\n",
    "Epoch 2 Step 1200 Loss 5.222508907318115\r\n",
    "Average Training Loss: 4.263375194536315\r\n",
    "Epoch 3 Step 100 Loss 4.717140197753906\r\n",
    "Epoch 3 Step 200 Loss 4.590120315551758\r\n",
    "Epoch 3 Step 300 Loss 4.780978202819824\r\n",
    "Epoch 3 Step 400 Loss 4.299923896789551\r\n",
    "Epoch 3 Step 500 Loss 4.794330596923828\r\n",
    "Epoch 3 Step 600 Loss 4.90772008895874\r\n",
    "Epoch 3 Step 700 Loss 5.2156596183776855\r\n",
    "Epoch 3 Step 800 Loss 4.793715953826904\r\n",
    "Epoch 3 Step 900 Loss 3.985318660736084\r\n",
    "Epoch 3 Step 1000 Loss 3.7246477603912354\r\n",
    "Epoch 3 Step 1100 Loss 3.602402687072754\r\n",
    "Epoch 3 Step 1200 Loss 4.329013347625732\r\n",
    "Average Training Loss: 4.173481227071197\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd386cc4-eea9-4af7-a691-b9fbe36981a1",
   "metadata": {},
   "outputs": [],
   "source": [
    " checkpoint = {\n",
    "   'model_state_dict': model.state_dict(),\n",
    "}\n",
    "torch.save(checkpoint, f'xlmnet_bs4_max_length1024_4e.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "93179b12-6c19-4156-9ab9-9e0a5b49edac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "def evaluate_rouge(model, val_loader, tokenizer, device):\n",
    "    rouge = load_metric('rouge')\n",
    "    model.eval()\n",
    "    for batch in val_loader:\n",
    "        input_ids, target_ids = batch\n",
    "        input_ids, target_ids = input_ids.to(device), target_ids.to(device)\n",
    "        \n",
    "        # Generate summaries\n",
    "        outputs = model.generate(input_ids=input_ids)\n",
    "        \n",
    "        # Decode the summaries\n",
    "        decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        decoded_labels = tokenizer.batch_decode(target_ids, skip_special_tokens=True)\n",
    "\n",
    "        # Compute Rouge score\n",
    "        rouge.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "    \n",
    "    # Calculate final score\n",
    "    result = rouge.compute()\n",
    "    for key in result.keys():\n",
    "        print(f\"{key}: {result[key].mid}\")\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "043bb9df-d7c5-4736-a5a0-248a91b18a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(text, model, tokenizer, device):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=1024, padding='max_length', truncation=True).to(device)\n",
    "    \n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(inputs['input_ids'], max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "86908831-6539-46e2-ba86-7843a4335ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_inputs, model_test_labels = preprocess_function(test_inputs, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8150c6be-1f26-4eb5-9fec-daf9b38dbf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TensorDataset\n",
    "test_dataset = TensorDataset(model_test_inputs['input_ids'], model_test_labels['input_ids'])\n",
    "\n",
    "# Create a DataLoader\n",
    "val_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90e7521a-8165-4f00-be97-e24e9ab37cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9441/769679038.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  rouge = load_metric('rouge')\n",
      "/mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages/datasets/load.py:752: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.0/metrics/rouge/rouge.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e517ab00522c4eb896013ac5b25a12fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1355: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/mnt/c/Users/Sergiu/Desktop/DLComp/venv/lib/python3.10/site-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 1024, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1: Score(precision=0.5682628637119129, recall=0.7606626781061232, fmeasure=0.6417841616651105)\n",
      "rouge2: Score(precision=0.3472802895392726, recall=0.4498331452513754, fmeasure=0.3873985543099933)\n",
      "rougeL: Score(precision=0.3939804996636087, recall=0.5136579508637882, fmeasure=0.4403192447961841)\n",
      "rougeLsum: Score(precision=0.3938001014396969, recall=0.5137175834759207, fmeasure=0.44015967536890516)\n"
     ]
    }
   ],
   "source": [
    "rouge_score = evaluate_rouge(model, val_loader, tokenizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcfc6b2-ee5c-49ad-a645-8283d3b0629a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d10714-df0a-4957-836d-a837a75bfc96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
